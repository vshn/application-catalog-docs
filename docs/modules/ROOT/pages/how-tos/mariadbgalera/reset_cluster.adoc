= How to Reset a Cluster (from node 0)

[WARNING]
====
If any other node than node 0 has further proceeded in transactions, this will result in data loss.
====

If the cluster lost a majority of nodes, it won't be able to start again on it's own.
Since it can't know which node has the latest data, you need to force the bootstrap.

See xref:how-tos/mariadbgalera/bootstrap_node.adoc[Bootstraping a Node] if you have to reset the cluster from another node than node 0.

Any of the following changes will be reset if a change to the MariaDB service (Crossplane composition) is being rolled out.

== Reset cluster to 1 node

.Save the instance ID of the affected cluster
[source,shell]
----
export INSTANCE_ID=<instance-id>
----

.Scale cluster to 1 replica
[source,shell]
----
kubectl -n $INSTANCE_ID scale statefulset mariadb \
    --replicas 1
----

.Enable force bootstrap
[source,shell]
----
kubectl -n $INSTANCE_ID set env statefulset/mariadb \
    -c mariadb-galera \
    MARIADB_GALERA_FORCE_SAFETOBOOTSTRAP="yes"
----

.If the nodes are already crashing or not ready, delete all pods
[source,shell]
----
kubectl -n $INSTANCE_ID delete pods -l app.kubernetes.io/name=mariadb-galera
----

== Restore cluster to 3 nodes

.Once the single node is bootstrapped and running, scale the cluster to 3
[source,shell]
----
kubectl -n $INSTANCE_ID scale statefulset mariadb \
    --replicas 3
----

.Finally disable force bootstrap again
[source,shell]
----
kubectl -n $INSTANCE_ID set env statefulset/mariadb -c mariadb-galera \
    MARIADB_GALERA_FORCE_SAFETOBOOTSTRAP="no"
----
