= Architecture Overview

AppCat is not a single monolithic thing.
It is composed of various different components that work together to provide AppCat.

image::architecture.drawio.png[]

== Component AppCat

The component is what glues most of AppCat's components together.
It's based on Project SYN and jsonnet.
It renders all necessary YAML manifests for us.

=== AppCat Monorepo

The monorepo contains most of AppCat's go code.
Some things live in other repos though, like the API Server or the Billing Collector for the cloudservices.

==== XFN Runner

The heart of AppCat's functionality.
We use Crossplane's composition functions to deploy a large part of our services.

The XFN runner is a custom implementation of Crossplane's runner.
Instead of relying on individual containers to trigger small groups of logic, our XFN runner is completely in-memory.

it interacts directly with Crossplane's GRPC interface and is running as a sidecar in the Crossplane Pod.
This is currently a limitation, as crossplane is not able to encrypt the communication between the XFN runner and Crossplane itself.
The communication is done via a local unix socket.

==== AppCat Controller

There are some limitations that can't be handled via the composition functions. Currently mainly these:

* Any after-deletion actions, Crossplane will not trigger any composition functions anymore after a claim/composite is deleted
* Webhooks, at the time we started, there was no support for webhooks on the claims, so we created our own webhook handler for the claims

==== SLA Reporter

We provide an optional guaranteed SLA.
This reporter handles the generation of monthly SLA reports that we can send out to our customers.

==== SLI Exporter

The basis of the SLAs are the SLIs.
This exporter handles the collection of SLI data for all the services.
It's based on Prometheus and Sloth.

==== Maintenance Runner

AppCat services feature fully automated, schedulable maintenance.
To actually do the maintenance we rely on the Maintenance Runner.

This runner is not one monolithic app, but rather a collection of Go modules that help doing maintenance for the various services.

=== AppCat API Server

The API Server provides some overview about the installed AppCat services on the given cluster.
It will also handle the listing of backups for any given service instance.

=== Statefulset Resizer

Because Kubernetes is not able to natively resize PVCs of a statefulset, we developed this controller.

It makes the resizing of a service instance seamless from the point of view of a user.

=== Sloth

A framework based on Prometheus queries that helps with generating SLO/SLA calculations.

=== Compositions

Although we heavily rely on composition functions, we also need P&T compositions to actually trigger the functions.

The component-appcat and jsonnet help with various functions to generate the rather verbose YAML manifests.

=== Billing Prometheus Rules

To integrate services provided by VSHN into the billing system, we deploy Prometheus rules to aggregate the billing metrics.

These rules can change depending on the given cluster.
APPUiO Cloud queries look different than APPUiO Managed queries.

=== Provider Definitions

In order to deploy all providers we rely on Crossplanes packages.
All Crossplane providers should provide such a package to make them manageable via Crossplane.
Crossplane then handles the lifecycle of the provider fully automated.
This includes the creation and maintenance of TLS certificates.

==== RBAC

The RBAC for the providers is also generated by the component and then deployed in such a way, that the provider service account get the right permissions.

== 3rd Party Operators

In order to deploy VSHN services we rely on 3rd party operators if they provide superior functionality compared to Helm charts.

Currently the only operator we use is StackGres.

== Component Crossplane

Component-crossplane manages the installation of crossplane itself.
It's also here where the XFN runner sidecar needs to be configured.

== Billing Collector Cloudservices

The collector connects to various clouds and queries them for the billing data of the given services.

It will then write these metrics directly to the billing system.
It does not go through Prometheus.
